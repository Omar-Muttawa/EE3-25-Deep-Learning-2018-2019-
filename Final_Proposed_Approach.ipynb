{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Proposed Approach.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CvCHEs3E3oXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Initialisation:**"
      ]
    },
    {
      "metadata": {
        "id": "Nw4w6OiR3t92",
        "colab_type": "code",
        "outputId": "a55c2c54-f341-4204-bd61-90c41b0d0fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras_triplet_descriptor'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 181 (delta 0), reused 1 (delta 0), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (181/181), 149.87 MiB | 8.43 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IjA_eDsrlYea",
        "colab_type": "code",
        "outputId": "2df37a6f-b7a3-45ee-b008-3c0eb0b2ba60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zh4HAWXqlasf",
        "colab_type": "code",
        "outputId": "62768cf7-8ec5-4ded-ddb1-02ced696e5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1357
        }
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-22 19:22:43--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.25.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.25.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-22 19:22:43--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-22 19:22:43--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.25.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.25.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!WeuYGubkELNTlUrqgPwt0DNs4VD2AKU9UEfF9xOHZemUQC38ooBrsV6qxtL-ucu3jwnQBbZXTLgSDzZAwaItE4DseRi-yv3sUjmtRd7ven780jYr866k-UDo-HDBzv2vDq5pST6Z0klRMQWWRCJQvn8AkuE_AMLB2XRjTOAR-3DgWrd9oyxi9UMqKvqjepWw8SQECas_6jW4jHlY8HGcLwdmkz7V56Kw4MWIEjvg3CXuhjFnR9NLhkGZvjhojId_rkQHp9_GF6IuLIu_ob8uVtWUNRDmj-CbiNE4KgXMhqWuxxlb3zLtccigN0EjSc4ku4Fy7WiaNAC2s0OgqLSEyWncGyFdIICuM1YoWjcyhogNbkOtKzDEacyEye_NQ8TTZjt7FQJTj2NVrXPeUtZK5FMU70mpL_aG8qC7_iXjr7b7S2H-p6mR-zkEy2EJk7LKrKRxOPZ3_ukdDOhMUI2sg8-22iOfzMCZy3-1iGdKdCQR_VDyriMfTwLfK2AFEojnv00aNGP7hEbYWt_P_g_0MZc_NyakWsEnoFpSbXeJeb5WRbC3pD_KDnBhu6VARguaGCi5NGqxyX2FVajZ7L4fVSRq7SbbKr9IzN7dBloxkmZ1iziiOzzscaMvnUdIVAX2kBRc2FimB94ZQfo53Bxi17bsvl7WUC1DPfK_LhbN8Y8y_hmnCIeTzPfHJNrD8wvxetWFeOEvAC6r-oQVBAdMgQ7CHWhzdybB5wiqvA1MUgrs8E29mNHvpLfoLV7zDPK7mMqU6Kiw1D4cJ3-_HdIRaLwUF71cBufZurVgmRyZGQWY44kgeBTsdF6Z8UxUzF_o8sK0LfnxnP9ckijFhzXwfVSRMvQkp5x_IJ97yBNOupRoilr_P5PXcE54bFhx_3AYPvlD6Ddajwur0javXEMQ2rDujADY90uiA-n6k1vLKCa4g1wheT5-AWwwkB2x2fBu-EfpSMy1u2VnbpfrXTjQ4PoeArP_v622SmDvZHz-49mt88R-zDwmxL862zmEOJQu94Ic0b9q7p5k0GiEPEVJvOHsr-dcq-l8cwkgS7DfzsssEU0en1eek1zczBFAskfGU-wj5eWV699FEd25XITympuyE2BLGhBPleSj3dpYiMQYrTdRKtCYln27KdvTs_T5nWOTfWQOyETLN0WfONzprVWWYxlUzFfuIqfVzv8fqeUYaPT8w3oUVtVdQ6SX6-pPYSZJQnx7ZIb4IEYOX5YEupzuvJQkOqLG7lAJck8yubtGN8GfM3RPn1zRBe_ZBUX2f2r5KIZlG7LqP5MMr6MYiCoTX36aQ2kmgSr6fBBUlVRk1V_7VJTNOY7hWZE7OulQhIUBKi2Hz-wu8xrxn5fxM7ljlQeAcHZbNa6pfp3O_vZmjbg6RZ3bPsVs8yDWhoj2CnQpA0zwswbeprmUw3XxQsnJMqL_ovWLrSq-spcafJaYPq4Be3PB3jeCR_pdYX15GZRKKsMzdm-oE4VjVxeAO3R7ADSsAZRd/download [following]\n",
            "--2019-03-22 19:22:44--  https://public.boxcloud.com/d/1/b1!WeuYGubkELNTlUrqgPwt0DNs4VD2AKU9UEfF9xOHZemUQC38ooBrsV6qxtL-ucu3jwnQBbZXTLgSDzZAwaItE4DseRi-yv3sUjmtRd7ven780jYr866k-UDo-HDBzv2vDq5pST6Z0klRMQWWRCJQvn8AkuE_AMLB2XRjTOAR-3DgWrd9oyxi9UMqKvqjepWw8SQECas_6jW4jHlY8HGcLwdmkz7V56Kw4MWIEjvg3CXuhjFnR9NLhkGZvjhojId_rkQHp9_GF6IuLIu_ob8uVtWUNRDmj-CbiNE4KgXMhqWuxxlb3zLtccigN0EjSc4ku4Fy7WiaNAC2s0OgqLSEyWncGyFdIICuM1YoWjcyhogNbkOtKzDEacyEye_NQ8TTZjt7FQJTj2NVrXPeUtZK5FMU70mpL_aG8qC7_iXjr7b7S2H-p6mR-zkEy2EJk7LKrKRxOPZ3_ukdDOhMUI2sg8-22iOfzMCZy3-1iGdKdCQR_VDyriMfTwLfK2AFEojnv00aNGP7hEbYWt_P_g_0MZc_NyakWsEnoFpSbXeJeb5WRbC3pD_KDnBhu6VARguaGCi5NGqxyX2FVajZ7L4fVSRq7SbbKr9IzN7dBloxkmZ1iziiOzzscaMvnUdIVAX2kBRc2FimB94ZQfo53Bxi17bsvl7WUC1DPfK_LhbN8Y8y_hmnCIeTzPfHJNrD8wvxetWFeOEvAC6r-oQVBAdMgQ7CHWhzdybB5wiqvA1MUgrs8E29mNHvpLfoLV7zDPK7mMqU6Kiw1D4cJ3-_HdIRaLwUF71cBufZurVgmRyZGQWY44kgeBTsdF6Z8UxUzF_o8sK0LfnxnP9ckijFhzXwfVSRMvQkp5x_IJ97yBNOupRoilr_P5PXcE54bFhx_3AYPvlD6Ddajwur0javXEMQ2rDujADY90uiA-n6k1vLKCa4g1wheT5-AWwwkB2x2fBu-EfpSMy1u2VnbpfrXTjQ4PoeArP_v622SmDvZHz-49mt88R-zDwmxL862zmEOJQu94Ic0b9q7p5k0GiEPEVJvOHsr-dcq-l8cwkgS7DfzsssEU0en1eek1zczBFAskfGU-wj5eWV699FEd25XITympuyE2BLGhBPleSj3dpYiMQYrTdRKtCYln27KdvTs_T5nWOTfWQOyETLN0WfONzprVWWYxlUzFfuIqfVzv8fqeUYaPT8w3oUVtVdQ6SX6-pPYSZJQnx7ZIb4IEYOX5YEupzuvJQkOqLG7lAJck8yubtGN8GfM3RPn1zRBe_ZBUX2f2r5KIZlG7LqP5MMr6MYiCoTX36aQ2kmgSr6fBBUlVRk1V_7VJTNOY7hWZE7OulQhIUBKi2Hz-wu8xrxn5fxM7ljlQeAcHZbNa6pfp3O_vZmjbg6RZ3bPsVs8yDWhoj2CnQpA0zwswbeprmUw3XxQsnJMqL_ovWLrSq-spcafJaYPq4Be3PB3jeCR_pdYX15GZRKKsMzdm-oE4VjVxeAO3R7ADSsAZRd/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.24.200, 107.152.25.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.24.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip    83%[===============>    ]   3.17G  21.8MB/s    eta 29s    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-47fd054e8ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JgTz84Eqlc7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vg5CLFdlftR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os, glob, datetime\n",
        "import keras\n",
        "import argparse\n",
        "import re\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate, Activation,Subtract\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNZ9pHI-lh_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#initialise seed\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8FMqky3lkYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define directories\n",
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqpmXBs3lx0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model_baseline(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder starts\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "    \n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv4)\n",
        "  \n",
        "  return shallow_net\n",
        "\n",
        "def get_denoise_model_UNET(shape):\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "\n",
        "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "\n",
        "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "  conv10 = Conv2D(1, 3,  padding = 'same')(conv9)\n",
        "\n",
        "  UNET2015 = Model(inputs = inputs, outputs = conv10)\n",
        "  \n",
        "  return UNET2015\n",
        "\n",
        "\n",
        "\n",
        "def get_descriptor_model(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "\n",
        "\n",
        "def DnCNN(depth,filters=64,image_channels=1, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n",
        "    # 1st layer, Conv+relu\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'conv'+str(layer_count))(inpt)\n",
        "    layer_count += 1\n",
        "    x = Activation('relu',name = 'relu'+str(layer_count))(x)\n",
        "    # depth-2 layers, Conv+BN+relu\n",
        "    for i in range(depth-2):\n",
        "        layer_count += 1\n",
        "        x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "        if use_bnorm:\n",
        "            layer_count += 1\n",
        "            #x = BatchNormalization(axis=3, momentum=0.1,epsilon=0.0001, name = 'bn'+str(layer_count))(x\n",
        "        x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "        layer_count += 1\n",
        "        x = Activation('relu',name = 'relu'+str(layer_count))(x)  \n",
        "    # last layer, Conv\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(3,3), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    x = Subtract(name = 'subtract' + str(layer_count))([inpt, x])   # input - noise\n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  # define loss\n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    #return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "    #return K.sum(K.square(y_pred - y_true), axis=-1)/2\n",
        "    return K.sum(K.square(y_pred - y_true))/2\n",
        "  \n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.001\n",
        "    if epoch<=30:\n",
        "        lr = initial_lr\n",
        "    elif epoch<=60:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=80:\n",
        "        lr = initial_lr/20 \n",
        "    else:\n",
        "        lr = initial_lr/20 \n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDhY-WWZpWTD",
        "colab_type": "code",
        "outputId": "04aa33ce-3ee2-4a37-ec3d-60cc7ea19dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "#Load Subset of NHPatches for Denoising\n",
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a3c3c0cdcb72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdenoise_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenoiseHPatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdenoise_generator_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenoiseHPatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DenoiseHPatches' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "i9crX8vi2YcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **EVALUATION OF DIFFERENT DENOISE MODELS:**"
      ]
    },
    {
      "metadata": {
        "id": "QZnTk0S-pvl5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load Shallow UNET for Base Line Evaluation\n",
        "shape = (32, 32, 1)\n",
        "denoise_model = get_denoise_model_baseline(shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NDG73LUqrYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the baseline UNET for 30 epochs in subset\n",
        "epochs = 30\n",
        "denoise_history_full=[]\n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val, callbacks=[lr_scheduler])\n",
        "  denoise_history_full.append(denoise_history)\n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save('denoise_baseline.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@denoise_baseline.h5\" https://file.io\n",
        "  print('Epoch Number= {}'.format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlCqGERGq1yP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in denoise_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_78qNPdIsBqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ULf0iurq-Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "#Must import 'descriptorbaselinecleansmall.h5' into directory\n",
        "descriptor_model_trip.set_weights(keras.models.load_model('./descriptorbaselinecleansmall.h5').get_weights())\n",
        "descriptor_model_trip.optimizer = keras.models.load_model('./descriptorbaselinecleansmall.h5').optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8ZA7ISZradc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-f51POxAsRcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsoyaE4osUbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCVaIMzCsYGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F6ZL99FEuNeK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load Full UNET for Evaluation\n",
        "shape = (32, 32, 1)\n",
        "denoise_model = get_denoise_model_UNET(shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "flPiEnFhuNeN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the  UNET for 30 epochs in subset\n",
        "epochs = 30\n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae'])\n",
        "denoise_history_full=[]\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val, callbacks=[lr_scheduler])\n",
        "  denoise_history_full.append(denoise_history)\n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save('denoise_UNET.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@denoise_UNET.h5\" https://file.io\n",
        "  print('Epoch Number= {}'.format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PDhbw7PYuNeQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in denoise_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qvLrKTuFuNeT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LePY__kCuNeU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "#Must import 'descriptorbaselinecleansmall.h5' into directory\n",
        "descriptor_model_trip.set_weights(keras.models.load_model('./descriptorbaselinecleansmall.h5').get_weights())\n",
        "descriptor_model_trip.optimizer = keras.models.load_model('./descriptorbaselinecleansmall.h5').optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sULXprjNuNeW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ObOR09mYuNeY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6Gjr-om0uNeb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zWQVApnKuNem",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X529cdNIub2k",
        "outputId": "84c87525-6d69-4ba2-9844-59e0023e212a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2706
        }
      },
      "cell_type": "code",
      "source": [
        "#Must upload model.h5\n",
        "#Load DnCNN +Transfer Network\n",
        "shape = (32, 32, 1)\n",
        "\n",
        "model_Dnn=DnCNN(depth=17,filters=64,image_channels=1,use_bnorm=True)\n",
        "model_Dnn.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n",
        "model_Dnn.load_weights('./model.h5')\n",
        "model_Dnn.summary()\n",
        "#define my model for end of denoiser\n",
        "\n",
        "#First Layers\n",
        "inpt = Input(shape=(None,None,1),name = 'input'+str(1))\n",
        "conv1 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(1))(inpt)\n",
        "activation1=Activation('relu',name = 'relu'+str(1))(conv1)\n",
        "#Middle Layers\n",
        "conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(2))(activation1)\n",
        "Norm2 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(2))(conv2)\n",
        "activation2=Activation('relu',name = 'relu'+str(2))(Norm2)\n",
        "\n",
        "conv3 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(3))(activation2)\n",
        "Norm3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(3))(conv3)\n",
        "activation3=Activation('relu',name = 'relu'+str(3))(Norm3)\n",
        "\n",
        "conv4 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(4))(activation3)\n",
        "Norm4 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(4))(conv4)\n",
        "activation4=Activation('relu',name = 'relu'+str(4))(Norm4)\n",
        "#Final Layers                       \n",
        "conv5 = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(5))(activation4)\n",
        "Norm5 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(5))(conv5)\n",
        "ErrorLayer=Subtract(name = 'subtract' + str(5))([inpt, Norm5])\n",
        "\n",
        "my_model=Model(inputs=inpt, outputs=ErrorLayer)\n",
        "my_model.summary()\n",
        "denoise_model=Sequential()\n",
        "denoise_model.add(model_Dnn)\n",
        "denoise_model.add(my_model)\n",
        "\n",
        "for layer in model_Dnn.layers:\n",
        "\tlayer.trainable = False\n",
        "  \n",
        "denoise_model.summary()\n",
        "\n",
        "for layer in model_Dnn.layers:\n",
        "\tlayer.trainable = False\n",
        "  \n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input0 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 640         input0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu2 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn4 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu5 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, None, None, 6 36864       relu5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn7 (BatchNormalization)        (None, None, None, 6 256         conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu8 (Activation)              (None, None, None, 6 0           bn7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv9 (Conv2D)                  (None, None, None, 6 36864       relu8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn10 (BatchNormalization)       (None, None, None, 6 256         conv9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu11 (Activation)             (None, None, None, 6 0           bn10[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv12 (Conv2D)                 (None, None, None, 6 36864       relu11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn13 (BatchNormalization)       (None, None, None, 6 256         conv12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu14 (Activation)             (None, None, None, 6 0           bn13[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv15 (Conv2D)                 (None, None, None, 6 36864       relu14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn16 (BatchNormalization)       (None, None, None, 6 256         conv15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu17 (Activation)             (None, None, None, 6 0           bn16[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv18 (Conv2D)                 (None, None, None, 6 36864       relu17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn19 (BatchNormalization)       (None, None, None, 6 256         conv18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu20 (Activation)             (None, None, None, 6 0           bn19[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv21 (Conv2D)                 (None, None, None, 6 36864       relu20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn22 (BatchNormalization)       (None, None, None, 6 256         conv21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu23 (Activation)             (None, None, None, 6 0           bn22[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv24 (Conv2D)                 (None, None, None, 6 36864       relu23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn25 (BatchNormalization)       (None, None, None, 6 256         conv24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu26 (Activation)             (None, None, None, 6 0           bn25[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv27 (Conv2D)                 (None, None, None, 6 36864       relu26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn28 (BatchNormalization)       (None, None, None, 6 256         conv27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu29 (Activation)             (None, None, None, 6 0           bn28[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv30 (Conv2D)                 (None, None, None, 6 36864       relu29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn31 (BatchNormalization)       (None, None, None, 6 256         conv30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu32 (Activation)             (None, None, None, 6 0           bn31[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv33 (Conv2D)                 (None, None, None, 6 36864       relu32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn34 (BatchNormalization)       (None, None, None, 6 256         conv33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu35 (Activation)             (None, None, None, 6 0           bn34[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv36 (Conv2D)                 (None, None, None, 6 36864       relu35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn37 (BatchNormalization)       (None, None, None, 6 256         conv36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu38 (Activation)             (None, None, None, 6 0           bn37[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv39 (Conv2D)                 (None, None, None, 6 36864       relu38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn40 (BatchNormalization)       (None, None, None, 6 256         conv39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu41 (Activation)             (None, None, None, 6 0           bn40[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv42 (Conv2D)                 (None, None, None, 6 36864       relu41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn43 (BatchNormalization)       (None, None, None, 6 256         conv42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu44 (Activation)             (None, None, None, 6 0           bn43[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv45 (Conv2D)                 (None, None, None, 6 36864       relu44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn46 (BatchNormalization)       (None, None, None, 6 256         conv45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu47 (Activation)             (None, None, None, 6 0           bn46[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv48 (Conv2D)                 (None, None, None, 1 576         relu47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "subtract49 (Subtract)           (None, None, None, 1 0           input0[0][0]                     \n",
            "                                                                 conv48[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 558,016\n",
            "Trainable params: 556,096\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 576         input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, None, None, 6 36864       relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2 (BatchNormalization)        (None, None, None, 6 256         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu2 (Activation)              (None, None, None, 6 0           bn2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn3 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu3 (Activation)              (None, None, None, 6 0           bn3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, None, None, 6 36864       relu3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn4 (BatchNormalization)        (None, None, None, 6 256         conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu4 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, None, None, 1 576         relu4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn5 (BatchNormalization)        (None, None, None, 1 4           conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "subtract5 (Subtract)            (None, None, None, 1 0           input1[0][0]                     \n",
            "                                                                 bn5[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 112,516\n",
            "Trainable params: 112,130\n",
            "Non-trainable params: 386\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, None, None, 1)     558016    \n",
            "_________________________________________________________________\n",
            "model_3 (Model)              (None, None, None, 1)     112516    \n",
            "=================================================================\n",
            "Total params: 670,532\n",
            "Trainable params: 112,130\n",
            "Non-trainable params: 558,402\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ij9ryBf0ub2n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the DnCNN for 30 epochs in subset\n",
        "epochs = 30\n",
        "#denoise_model= keras.models.load_model('./Final denoise 2 epoch.h5',custom_objects={'sum_squared_error':sum_squared_error})\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "denoise_history_full=[]\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val, callbacks=[lr_scheduler])\n",
        "  denoise_history_full.append(denoise_history)\n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save('denoise_DnCNN.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@denoise_DnCNN.h5\" https://file.io\n",
        "  print('Epoch Number= {}'.format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iiqpHF8Fub2q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in denoise_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ShNnfVz4ub2s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XVn_k0w2ub2v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "#Must import 'descriptorbaselinecleansmall.h5' into directory\n",
        "descriptor_model_trip.set_weights(keras.models.load_model('./descriptorbaselinecleansmall.h5').get_weights())\n",
        "descriptor_model_trip.optimizer = keras.models.load_model('./descriptorbaselinecleansmall.h5').optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lg-ipx4-ub2w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fLzal6kcub2y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BGS9z5QPub22",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F7du1--iub24",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXoayGrk2JwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **DESCRIPTOR NOISY DENOISED CLEAN TESTS**"
      ]
    },
    {
      "metadata": {
        "id": "vqRsWmU3wkMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Baseline Descriptor on Noisy\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ftuSDRaw-4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=10000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOyvM3AGxaXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEQvr-55xcgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_noisy.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_noisy.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTQQ4jOZxmA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdpzQ1iZx6gh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Must Include 'UNETsmall.h5' in directory\n",
        "shape = (32, 32, 1)\n",
        "denoise_model=get_denoise_model_UNET(shape)\n",
        "denoise_model= keras.models.load_model('./UNETsmall.h5')\n",
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nwVBRNvOy4N5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "647qRwPfy4N8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mCVGslI1y4N_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oI4PgFiry9do",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Baseline Descriptor on Clean\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1NrcawAXy9dq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=10000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TBgysNH_y9du",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C2DRfMuGy9dw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_clean.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_clean.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8wUY2Ptmy9dy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mgPP8qFky9d2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Must Include 'UNETsmall.h5' in directory\n",
        "shape = (32, 32, 1)\n",
        "denoise_model=get_denoise_model_UNET(shape)\n",
        "denoise_model= keras.models.load_model('./UNETsmall.h5')\n",
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t_Fed8Qhy9d4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ujzZ4gs3y9d8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0EKduHnPy9d_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mYM2UmG2zKT_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Baseline Descriptor on Denoised\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QVvbpSkNzKUD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Must Include 'UNETsmall.h5' in directory\n",
        "shape = (32, 32, 1)\n",
        "denoise_model=get_denoise_model_UNET(shape)\n",
        "denoise_model= keras.models.load_model('./UNETsmall.h5')\n",
        "\n",
        "### Descriptor loading and training for 10,0000 Triplets\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=10000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "os84tQwrzKUF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uXzg_PTOzKUG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_denoised.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_denoised.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TciDT_2szKUJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zbk0eyRvzKUL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5nbYdaqjzKUN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mskY2DApzKUQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v65jpwGPzKUU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5zdcfzh179q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **TRIPLET GENERATION Tests:**"
      ]
    },
    {
      "metadata": {
        "id": "BY6liieD0PgK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Testing Tough Positv\n",
        "#Must include 'read_data_tough_postive.py'\n",
        "from read_data_tough_positive import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6dAOqlp73FMh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Baseline Descriptor for tough_positives on clean images:\n",
        "\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EHsTuuea3FMj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets Trained on Clean \n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=10000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZPT7ilU43FMl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lssS6oNE3FMo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_toughpositive.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_toughpositive.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CKzJgvyS3FMr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fAETZUYD3FMs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tested on clean images upperbound\n",
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=None, use_clean=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2vDnDsvx3FMu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ka34bju03FMw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2_pNbp6V3FM0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XTt2Fjy634of",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Testing farnegative\n",
        "#Must include 'read_data_farnegative.py'\n",
        "from read_data_tough_farnegative import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "okRfa4jx34oh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Baseline Descriptor for tough_positives on clean images:\n",
        "\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M4U9KU4S34oj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets Trained on Clean \n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=10000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mal1DxQ_34om",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tush6D9U34oq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_farnegative.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_farnegative.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aBBPZ1cq34ou",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CJyIcw6l34ow",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tested on clean images upperbound\n",
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=None, use_clean=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NIsKgf5834ox",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IgQ6BtK634oz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d6VY69E-34o2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJtUJ9jh4ob4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **FINAL PROPOSED APPROACH:**"
      ]
    },
    {
      "metadata": {
        "id": "dySOZFJM5ptS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FsEbe9u5oQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#initialise seed\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ld1yJF1N5y7_",
        "colab_type": "code",
        "outputId": "2ff4cb20-704e-481c-c4b5-75d42811f86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Load Full Data Set\n",
        "denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XAIjcA_L4xke",
        "colab_type": "code",
        "outputId": "6820c5ba-eabb-468d-bdb5-a160ab6854a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2706
        }
      },
      "cell_type": "code",
      "source": [
        "#Load DnCNN +Transfer Network\n",
        "shape = (32, 32, 1)\n",
        "\n",
        "model_Dnn=DnCNN(depth=17,filters=64,image_channels=1,use_bnorm=True)\n",
        "model_Dnn.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n",
        "model_Dnn.load_weights('./model.h5')\n",
        "model_Dnn.summary()\n",
        "#define my model for end of denoiser\n",
        "\n",
        "#First Layers\n",
        "inpt = Input(shape=(None,None,1),name = 'input'+str(1))\n",
        "conv1 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(1))(inpt)\n",
        "activation1=Activation('relu',name = 'relu'+str(1))(conv1)\n",
        "#Middle Layers\n",
        "conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(2))(activation1)\n",
        "Norm2 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(2))(conv2)\n",
        "activation2=Activation('relu',name = 'relu'+str(2))(Norm2)\n",
        "\n",
        "conv3 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(3))(activation2)\n",
        "Norm3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(3))(conv3)\n",
        "activation3=Activation('relu',name = 'relu'+str(3))(Norm3)\n",
        "\n",
        "conv4 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(4))(activation3)\n",
        "Norm4 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(4))(conv4)\n",
        "activation4=Activation('relu',name = 'relu'+str(4))(Norm4)\n",
        "#Final Layers                       \n",
        "conv5 = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(5))(activation4)\n",
        "Norm5 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(5))(conv5)\n",
        "ErrorLayer=Subtract(name = 'subtract' + str(5))([inpt, Norm5])\n",
        "\n",
        "my_model=Model(inputs=inpt, outputs=ErrorLayer)\n",
        "my_model.summary()\n",
        "denoise_model=Sequential()\n",
        "denoise_model.add(model_Dnn)\n",
        "denoise_model.add(my_model)\n",
        "\n",
        "for layer in model_Dnn.layers:\n",
        "\tlayer.trainable = False\n",
        "  \n",
        "denoise_model.summary()\n",
        "\n",
        "for layer in model_Dnn.layers:\n",
        "\tlayer.trainable = False\n",
        "  \n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "denoise_model.compile(optimizer=Adam(0.001), loss=sum_squared_error)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input0 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 640         input0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu2 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn4 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu5 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, None, None, 6 36864       relu5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn7 (BatchNormalization)        (None, None, None, 6 256         conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu8 (Activation)              (None, None, None, 6 0           bn7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv9 (Conv2D)                  (None, None, None, 6 36864       relu8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn10 (BatchNormalization)       (None, None, None, 6 256         conv9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu11 (Activation)             (None, None, None, 6 0           bn10[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv12 (Conv2D)                 (None, None, None, 6 36864       relu11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn13 (BatchNormalization)       (None, None, None, 6 256         conv12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu14 (Activation)             (None, None, None, 6 0           bn13[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv15 (Conv2D)                 (None, None, None, 6 36864       relu14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn16 (BatchNormalization)       (None, None, None, 6 256         conv15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu17 (Activation)             (None, None, None, 6 0           bn16[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv18 (Conv2D)                 (None, None, None, 6 36864       relu17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn19 (BatchNormalization)       (None, None, None, 6 256         conv18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu20 (Activation)             (None, None, None, 6 0           bn19[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv21 (Conv2D)                 (None, None, None, 6 36864       relu20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn22 (BatchNormalization)       (None, None, None, 6 256         conv21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu23 (Activation)             (None, None, None, 6 0           bn22[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv24 (Conv2D)                 (None, None, None, 6 36864       relu23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn25 (BatchNormalization)       (None, None, None, 6 256         conv24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu26 (Activation)             (None, None, None, 6 0           bn25[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv27 (Conv2D)                 (None, None, None, 6 36864       relu26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn28 (BatchNormalization)       (None, None, None, 6 256         conv27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu29 (Activation)             (None, None, None, 6 0           bn28[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv30 (Conv2D)                 (None, None, None, 6 36864       relu29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn31 (BatchNormalization)       (None, None, None, 6 256         conv30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu32 (Activation)             (None, None, None, 6 0           bn31[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv33 (Conv2D)                 (None, None, None, 6 36864       relu32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn34 (BatchNormalization)       (None, None, None, 6 256         conv33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu35 (Activation)             (None, None, None, 6 0           bn34[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv36 (Conv2D)                 (None, None, None, 6 36864       relu35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn37 (BatchNormalization)       (None, None, None, 6 256         conv36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu38 (Activation)             (None, None, None, 6 0           bn37[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv39 (Conv2D)                 (None, None, None, 6 36864       relu38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn40 (BatchNormalization)       (None, None, None, 6 256         conv39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu41 (Activation)             (None, None, None, 6 0           bn40[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv42 (Conv2D)                 (None, None, None, 6 36864       relu41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn43 (BatchNormalization)       (None, None, None, 6 256         conv42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu44 (Activation)             (None, None, None, 6 0           bn43[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv45 (Conv2D)                 (None, None, None, 6 36864       relu44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn46 (BatchNormalization)       (None, None, None, 6 256         conv45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu47 (Activation)             (None, None, None, 6 0           bn46[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv48 (Conv2D)                 (None, None, None, 1 576         relu47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "subtract49 (Subtract)           (None, None, None, 1 0           input0[0][0]                     \n",
            "                                                                 conv48[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 558,016\n",
            "Trainable params: 556,096\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 576         input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, None, None, 6 36864       relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2 (BatchNormalization)        (None, None, None, 6 256         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu2 (Activation)              (None, None, None, 6 0           bn2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn3 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu3 (Activation)              (None, None, None, 6 0           bn3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, None, None, 6 36864       relu3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn4 (BatchNormalization)        (None, None, None, 6 256         conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu4 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, None, None, 1 576         relu4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn5 (BatchNormalization)        (None, None, None, 1 4           conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "subtract5 (Subtract)            (None, None, None, 1 0           input1[0][0]                     \n",
            "                                                                 bn5[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 112,516\n",
            "Trainable params: 112,130\n",
            "Non-trainable params: 386\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, None, None, 1)     558016    \n",
            "_________________________________________________________________\n",
            "model_3 (Model)              (None, None, None, 1)     112516    \n",
            "=================================================================\n",
            "Total params: 670,532\n",
            "Trainable params: 112,130\n",
            "Non-trainable params: 558,402\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yRojq5CE5Mju",
        "colab_type": "code",
        "outputId": "f559a07e-4ec1-48b2-8dbf-2d165d7446c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1119
        }
      },
      "cell_type": "code",
      "source": [
        "#Train the DnCNN for 30 epochs on Full \n",
        "epochs = 30\n",
        "#denoise_model= keras.models.load_model('./Final denoise 2 epoch.h5',custom_objects={'sum_squared_error':sum_squared_error})\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "denoise_history_full=[]\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val, callbacks=[lr_scheduler])\n",
        "  denoise_history_full.append(denoise_history)\n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save('denoise_DnCNN_full.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@denoise_DnCNN_full.h5\" https://file.io\n",
        "  print('Epoch Number= {}'.format(e))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 123/1545 [=>............................] - ETA: 1:19:10 - loss: 12090194.2683"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0d933c94e35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n\u001b[1;32m     10\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                                 validation_data=denoise_generator_val, callbacks=[lr_scheduler])\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mdenoise_history_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoise_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m### Saves optimizer and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d1Xh6d1_8Zuj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from read_data_tough_positive import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKh5wj1r6vFZ",
        "colab_type": "code",
        "outputId": "2a749030-d582-4995-f4c2-705c7c1b2ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Load Baseline Descriptor\n",
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CRc-2B6I8w73",
        "colab_type": "code",
        "outputId": "9d1d1736-2ba5-4eaf-c8ce-3317c2c49842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets Trained on Clean using Tough Positive \n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:35<00:00,  3.30it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 23089.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "  0%|          | 0/116 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 116/116 [00:22<00:00,  3.11it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 64449.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "if7tR-bk9DGh",
        "outputId": "fa197bcd-c166-4b71-ba96-7c9b0a50678c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "cell_type": "code",
      "source": [
        "#Train on tough_positive for 10 epochs\n",
        "epochs = 10\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_farnegative.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_farnegative.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.3514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 33598.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 473s 2s/step - loss: 0.3508 - val_loss: 0.5961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 60996.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"t7VmyB\",\"link\":\"https://file.io/t7VmyB\",\"expiry\":\"14 days\"}EPOCH NUMBER: 0\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.2909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 24834.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 469s 2s/step - loss: 0.2912 - val_loss: 0.4095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 70689.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"8f7OiI\",\"link\":\"https://file.io/8f7OiI\",\"expiry\":\"14 days\"}EPOCH NUMBER: 1\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.2588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 38022.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 475s 2s/step - loss: 0.2585 - val_loss: 0.3675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 68653.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"T1EYjm\",\"link\":\"https://file.io/T1EYjm\",\"expiry\":\"14 days\"}EPOCH NUMBER: 2\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.2756"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 30691.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 473s 2s/step - loss: 0.2757 - val_loss: 0.3282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 70780.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"JACEPl\",\"link\":\"https://file.io/JACEPl\",\"expiry\":\"14 days\"}EPOCH NUMBER: 3\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.2743"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 8422.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 475s 2s/step - loss: 0.2741 - val_loss: 0.3478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 49785.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"5uVcMb\",\"link\":\"https://file.io/5uVcMb\",\"expiry\":\"14 days\"}EPOCH NUMBER: 4\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.2767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 27468.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 478s 2s/step - loss: 0.2761 - val_loss: 0.3259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 70906.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"A5Ss8F\",\"link\":\"https://file.io/A5Ss8F\",\"expiry\":\"14 days\"}EPOCH NUMBER: 5\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.3095"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 34880.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 474s 2s/step - loss: 0.3095 - val_loss: 0.4046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 69806.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"5TmXMg\",\"link\":\"https://file.io/5TmXMg\",\"expiry\":\"14 days\"}EPOCH NUMBER: 6\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.3136"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 25182.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 474s 2s/step - loss: 0.3127 - val_loss: 0.4027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 71010.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"2Ck3gh\",\"link\":\"https://file.io/2Ck3gh\",\"expiry\":\"14 days\"}EPOCH NUMBER: 7\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.3457"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 30497.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 474s 2s/step - loss: 0.3458 - val_loss: 0.6604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 67890.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"6PcWm8\",\"link\":\"https://file.io/6PcWm8\",\"expiry\":\"14 days\"}EPOCH NUMBER: 8\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.3913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 22972.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 476s 2s/step - loss: 0.3926 - val_loss: 0.4289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 68917.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"L6rMMh\",\"link\":\"https://file.io/L6rMMh\",\"expiry\":\"14 days\"}EPOCH NUMBER: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HAK1QWox9DGj",
        "outputId": "0a01115e-d619-4e90-b73b-e4f0b2fde091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': [0.5960797265172004], 'loss': [0.35076710890978574]}\n",
            "{'val_loss': [0.4094816155731678], 'loss': [0.2912413223832846]}\n",
            "{'val_loss': [0.36746436953544614], 'loss': [0.2584550421498716]}\n",
            "{'val_loss': [0.32817778959870336], 'loss': [0.27568794777151195]}\n",
            "{'val_loss': [0.3477799784392118], 'loss': [0.27408573728054764]}\n",
            "{'val_loss': [0.3259496470913291], 'loss': [0.27608541514724494]}\n",
            "{'val_loss': [0.4046412229537964], 'loss': [0.3094890217622742]}\n",
            "{'val_loss': [0.402709629945457], 'loss': [0.31274959692033005]}\n",
            "{'val_loss': [0.6603823687881232], 'loss': [0.34584213881753384]}\n",
            "{'val_loss': [0.4288881026208401], 'loss': [0.39256305201910435]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Dt9y2W8X9PiQ",
        "outputId": "a6b249f6-664f-48da-dea6-5df7bc06a3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets Trained on Clean using Tough Positive \n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:37<00:00,  3.10it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 68070.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using clean patches\n",
            "100%|██████████| 116/116 [00:21<00:00,  3.13it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 68878.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cNC0sFrD9V4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d37ObY8g9PiR",
        "outputId": "d3127118-41ac-4df5-f9e6-320f69289b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2054
        }
      },
      "cell_type": "code",
      "source": [
        "#Train on regular for 35 epochs\n",
        "epochs = 35\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_farnegative.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_farnegative.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.4195"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 34572.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 465s 2s/step - loss: 0.4214 - val_loss: 0.7304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 68062.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"TR7T7A\",\"link\":\"https://file.io/TR7T7A\",\"expiry\":\"14 days\"}EPOCH NUMBER: 0\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.5092"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 23178.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 465s 2s/step - loss: 0.5094 - val_loss: 1.8428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 66808.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"6NUBOB\",\"link\":\"https://file.io/6NUBOB\",\"expiry\":\"14 days\"}EPOCH NUMBER: 1\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.7336"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 25890.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 462s 2s/step - loss: 0.7349 - val_loss: 0.8574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 64424.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"d9WqjQ\",\"link\":\"https://file.io/d9WqjQ\",\"expiry\":\"14 days\"}EPOCH NUMBER: 2\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 1.7268"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 33953.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 474s 2s/step - loss: 1.7260 - val_loss: 9.7739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 68564.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"JnuA7r\",\"link\":\"https://file.io/JnuA7r\",\"expiry\":\"14 days\"}EPOCH NUMBER: 3\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 413278055798.1710"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 29702.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 479s 2s/step - loss: 411211665519.1802 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 48488.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"DretJ5\",\"link\":\"https://file.io/DretJ5\",\"expiry\":\"14 days\"}EPOCH NUMBER: 4\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 19924.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 479s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 67420.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"VzxmyP\",\"link\":\"https://file.io/VzxmyP\",\"expiry\":\"14 days\"}EPOCH NUMBER: 5\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 19715.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 478s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 61843.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"HZBnGL\",\"link\":\"https://file.io/HZBnGL\",\"expiry\":\"14 days\"}EPOCH NUMBER: 6\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 34489.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 475s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 66136.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"HvM5ef\",\"link\":\"https://file.io/HvM5ef\",\"expiry\":\"14 days\"}EPOCH NUMBER: 7\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 29353.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 474s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 53539.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"JU6qZP\",\"link\":\"https://file.io/JU6qZP\",\"expiry\":\"14 days\"}EPOCH NUMBER: 8\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 8587.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 477s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 52995.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"BpbqdQ\",\"link\":\"https://file.io/BpbqdQ\",\"expiry\":\"14 days\"}EPOCH NUMBER: 9\n",
            "Epoch 1/1\n",
            "199/200 [============================>.] - ETA: 2s - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 31108.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 473s 2s/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 60773.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"success\":true,\"key\":\"vAJKoP\",\"link\":\"https://file.io/vAJKoP\",\"expiry\":\"14 days\"}EPOCH NUMBER: 10\n",
            "Epoch 1/1\n",
            "160/200 [=======================>......] - ETA: 1:32 - loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-52bb4291a330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mdescriptor_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_model_trip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mdescriptor_history_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptor_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m### Saves optimizer and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-_rJuUxr9PiT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hGxdiCgz9qlB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from read_data_farnegative.py import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0QaJSYN6LvUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training for 10,0000 Triplets Trained on Clean using Tough Positive \n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=None, use_clean=True)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mW1Xpxn19qlD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train on farnegative for 5 epochs\n",
        "epochs = 5\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "descriptor_history_full=[]\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  descriptor_history_full.append(descriptor_history)\n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor_farnegative.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  !curl -F \"file=@descriptor_farnegative.h5\" https://file.io\n",
        "  print(\"EPOCH NUMBER: {}\".format(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hSTASvhi9qlF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in descriptor_history_full:\n",
        "  print(epoch.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bOdFx73M-AVT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "denoise_model= keras.models.load_model('./DnCnn+TransferCnn.h5',custom_objects={'sum_squared_error':sum_squared_error})\n",
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tk0E2T3_-AVX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Verification:\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8Mxpxh2E-AVZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image Matching\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dPQ2Fl57-AVa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Patch Retrieval\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vq_i6Jk6-iUH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Compressing and Saving:**"
      ]
    },
    {
      "metadata": {
        "id": "hKue6UzB-o57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -rq descriptors.zip ./out/custom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHcIYVhM-rkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "\n",
        "  media = MediaFileUpload(path, \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                  media_body=media,\n",
        "                                  fields='id').execute()\n",
        "\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "  return created"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6bQrYoF-u36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}